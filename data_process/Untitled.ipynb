{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd53c65-3678-4de0-8c6a-b80d7e9a649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_processed_data_for_day(file_path):\n",
    "    \"\"\"\n",
    "    加载处理后的SMART数据文件（每个日期的文件）\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def load_all_smart_data(smart_data_base_folder):\n",
    "    \"\"\"\n",
    "    一次性加载所有SMART数据文件到内存。\n",
    "    \"\"\"\n",
    "    all_smart_data = []\n",
    "\n",
    "    # 遍历文件夹中所有csv文件\n",
    "    for filename in tqdm(os.listdir(smart_data_base_folder)[:30]):\n",
    "        if filename.endswith('_processed.csv'):\n",
    "            file_path = os.path.join(smart_data_base_folder, filename)\n",
    "            smart_data = pd.read_csv(file_path)\n",
    "            smart_data['ds'] = pd.to_datetime(smart_data['ds'])  # 确保 'ds' 列为 datetime 类型\n",
    "            all_smart_data.append(smart_data)\n",
    "\n",
    "    # 合并所有的 DataFrame\n",
    "    return pd.concat(all_smart_data, ignore_index=True)\n",
    "\n",
    "\n",
    "def find_files_in_date_range(base_folder, start_date, end_date):\n",
    "    \"\"\"\n",
    "    根据给定的日期范围查找需要加载的文件\n",
    "    \"\"\"\n",
    "    # 将日期范围转为字符串（例如：20180101）\n",
    "    start_date_str = start_date.strftime('%Y%m%d')\n",
    "    end_date_str = end_date.strftime('%Y%m%d')\n",
    "    \n",
    "    # 获取所有文件并按日期排序\n",
    "    all_files = sorted([f for f in os.listdir(base_folder) if f.endswith('_processed.csv')])\n",
    "    \n",
    "    # 根据日期范围筛选文件\n",
    "    relevant_files = [os.path.join(base_folder, f) for f in all_files if start_date_str <= f[:8] <= end_date_str]\n",
    "    \n",
    "    return relevant_files\n",
    "\n",
    "\n",
    "\n",
    "def generate_features_and_labels(failure_data, smart_data_base_folder, lookback_days, window_size, step_size):\n",
    "    \"\"\"\n",
    "    生成模型训练数据，按给定的滑动窗口选择特征和标签。\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # 按照 'failure_time' 升序排序 failure_data\n",
    "    failure_data = failure_data.sort_values(by='failure_time')\n",
    "    \n",
    "    print(f'Loading Data ...')\n",
    "    # 预先加载所有的SMART数据\n",
    "    all_smart_data = load_all_smart_data(smart_data_base_folder)\n",
    "    print(f'Loading Data Success')\n",
    "\n",
    "    # 过滤掉在给定时间范围内的失败数据\n",
    "    failure_data = failure_data[(failure_data['failure_time'] >= start_date) & (failure_data['failure_time'] <= end_date)]\n",
    "\n",
    "    # 生成特征和标签\n",
    "    for failure in tqdm(failure_data.itertuples(), desc=\"Processing failure events\"):\n",
    "        failure_time = failure.failure_time\n",
    "        disk_id = failure.disk_id\n",
    "        model = failure.model\n",
    "        \n",
    "        # 计算前 lookback_days 天的时间范围\n",
    "        start_time = failure_time - timedelta(days=lookback_days)\n",
    "        end_time = failure_time\n",
    "        \n",
    "        # 筛选出在时间范围内的SMART数据\n",
    "        relevant_smart_data = all_smart_data[(all_smart_data['disk_id'] == disk_id) & \n",
    "                                             (all_smart_data['model'] == model) & \n",
    "                                             (all_smart_data['ds'] >= start_time) & \n",
    "                                             (all_smart_data['ds'] <= end_time)]\n",
    "\n",
    "        # 滑动窗口处理\n",
    "        for i in range(0, lookback_days - window_size + 1, step_size):\n",
    "            window_data = []\n",
    "\n",
    "            # 获取窗口内的时间段\n",
    "            window_start_time = failure_time - timedelta(days=(lookback_days - i))\n",
    "            window_end_time = window_start_time + timedelta(days=window_size)\n",
    "            \n",
    "            # 筛选出时间段内的数据\n",
    "            window_data_for_window = relevant_smart_data[(relevant_smart_data['ds'] >= window_start_time) & \n",
    "                                                        (relevant_smart_data['ds'] < window_end_time)]\n",
    "            \n",
    "            if not window_data_for_window.empty:\n",
    "                # 获取该窗口内的所有特征\n",
    "                values = window_data_for_window.drop(columns=['disk_id', 'label']).values.tolist()\n",
    "\n",
    "                # 获取窗口内最后一条数据\n",
    "                last_window_data = window_data_for_window.iloc[-1]\n",
    "                \n",
    "                # 计算标签，基于最后一条数据的时间\n",
    "                label = last_window_data['label']\n",
    "                \n",
    "                # 将窗口内的特征和标签添加到 all_data 列表\n",
    "                all_data.append({'data': values, 'label': label})\n",
    "                print(all_data[-1])\n",
    "    \n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03d8ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_data_base_folder = '/mnt/raid5/sum/card/storage/StreamDFP/dataset/processed_smart_data'  # 设置为存放处理过的数据文件夹\n",
    "\n",
    "\n",
    "lookback_days = 20  # 前30天的数据\n",
    "window_size = 10  # 每个窗口大小为10天\n",
    "step_size = 5  # 每次滑动1天\n",
    "separator = '<SEP>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, smart_data_base_folder, lookback_days=None, window_size = 10, step_size = 5, separator='<SEP>'):\n",
    "        \"\"\"\n",
    "        初始化 Dataset 类\n",
    "        :param data: pandas.DataFrame，包含滑动窗口后的数据，每行是一个样本\n",
    "        :param tokenizer: 可选，用于将文本序列转换为 token 的函数\n",
    "        :param separator: 分隔符，用于分割窗口内的数据\n",
    "        \"\"\"\n",
    "        self.smart_data_base_folder = smart_data_base_folder\n",
    "        self.lookback_days = lookback_days\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.separator = separator\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集大小\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取数据集中的第 idx 个样本\n",
    "        :param idx: 索引\n",
    "        :return: 样本字典，包括序列化数据和标签\n",
    "        \"\"\"\n",
    "        # 获取序列化数据和标签\n",
    "        row = self.data.iloc[idx]\n",
    "        serialized_data = row['serialized_data']\n",
    "        label = row['label']\n",
    "        \n",
    "        # 可选：将序列化数据 token 化（如果提供了 tokenizer）\n",
    "        if self.tokenizer:\n",
    "            serialized_data = self.tokenizer(self.separator.join(serialized_data))\n",
    "        else:\n",
    "            # 默认转换为 tensor\n",
    "            serialized_data = torch.tensor(serialized_data, dtype=torch.float32)\n",
    "        \n",
    "        # 返回样本\n",
    "        return {\n",
    "            'data': serialized_data,\n",
    "            'label': torch.tensor(label, dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c402228-feb4-40e0-a48d-9c250bee4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:05,  5.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Success\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# 每次滑动1天\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 生成特征和标签数据集\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_features_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfailure_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmart_data_base_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookback_days\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 查看生成的DataFrame\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[2], line 64\u001b[0m, in \u001b[0;36mgenerate_features_and_labels\u001b[0;34m(failure_data, smart_data_base_folder, lookback_days, window_size, step_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading Data Success\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 过滤掉在给定时间范围内的失败数据\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m failure_data \u001b[38;5;241m=\u001b[39m failure_data[(failure_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailure_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mstart_date\u001b[49m) \u001b[38;5;241m&\u001b[39m (failure_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailure_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date)]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 生成特征和标签\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m failure \u001b[38;5;129;01min\u001b[39;00m tqdm(failure_data\u001b[38;5;241m.\u001b[39mitertuples(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing failure events\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_date' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 调用函数的示例\n",
    "smart_data_base_folder = '/mnt/raid5/sum/card/storage/StreamDFP/dataset/processed_smart_data'  # 设置为存放处理过的数据文件夹\n",
    "\n",
    "\n",
    "lookback_days = 20  # 前30天的数据\n",
    "window_size = 10  # 每个窗口大小为10天\n",
    "step_size = 5  # 每次滑动1天\n",
    "\n",
    "# 生成特征和标签数据集\n",
    "dataset = generate_features_and_labels(failure_data, smart_data_base_folder, lookback_days, window_size, step_size)\n",
    "\n",
    "# 查看生成的DataFrame\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fa7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_file_path = '/mnt/raid5/sum/card/storage/StreamDFP/dataset/ssd_failure_label.csv'  # 设置为failure数据的路径\n",
    "\n",
    "# 加载失败数据\n",
    "failure_data = pd.read_csv(failure_file_path)\n",
    "failure_data['failure_time'] = pd.to_datetime(failure_data['failure_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67c8256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>failure_time</th>\n",
       "      <th>disk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2019-03-22 10:24:38</td>\n",
       "      <td>4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2019-02-22 04:56:06</td>\n",
       "      <td>82064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2018-12-17 12:16:33</td>\n",
       "      <td>32311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2018-05-19 17:32:03</td>\n",
       "      <td>18316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2018-10-25 04:00:50</td>\n",
       "      <td>32466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model        failure_time  disk_id\n",
       "0   MA2 2019-03-22 10:24:38     4711\n",
       "1   MA2 2019-02-22 04:56:06    82064\n",
       "2   MA2 2018-12-17 12:16:33    32311\n",
       "3   MA2 2018-05-19 17:32:03    18316\n",
       "4   MA2 2018-10-25 04:00:50    32466"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fa76b",
   "metadata": {},
   "source": [
    "首先对failure_data升序排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccb8c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>failure_time</th>\n",
       "      <th>disk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2018-01-02 19:15:32</td>\n",
       "      <td>33722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2018-01-02 22:45:16</td>\n",
       "      <td>58337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>MA1</td>\n",
       "      <td>2018-01-03 03:23:44</td>\n",
       "      <td>26378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>MA1</td>\n",
       "      <td>2018-01-03 03:29:27</td>\n",
       "      <td>39876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13424</th>\n",
       "      <td>MC1</td>\n",
       "      <td>2018-01-03 05:03:03</td>\n",
       "      <td>199348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>MC2</td>\n",
       "      <td>2019-12-31 16:16:05</td>\n",
       "      <td>12463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16066</th>\n",
       "      <td>MC2</td>\n",
       "      <td>2019-12-31 19:28:04</td>\n",
       "      <td>10186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13278</th>\n",
       "      <td>MC1</td>\n",
       "      <td>2019-12-31 19:32:50</td>\n",
       "      <td>18144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2019-12-31 21:57:36</td>\n",
       "      <td>99516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>MB1</td>\n",
       "      <td>2019-12-31 22:58:47</td>\n",
       "      <td>29755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16305 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model        failure_time  disk_id\n",
       "309     MA2 2018-01-02 19:15:32    33722\n",
       "293     MA2 2018-01-02 22:45:16    58337\n",
       "2197    MA1 2018-01-03 03:23:44    26378\n",
       "2001    MA1 2018-01-03 03:29:27    39876\n",
       "13424   MC1 2018-01-03 05:03:03   199348\n",
       "...     ...                 ...      ...\n",
       "16226   MC2 2019-12-31 16:16:05    12463\n",
       "16066   MC2 2019-12-31 19:28:04    10186\n",
       "13278   MC1 2019-12-31 19:32:50    18144\n",
       "602     MA2 2019-12-31 21:57:36    99516\n",
       "4402    MB1 2019-12-31 22:58:47    29755\n",
       "\n",
       "[16305 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_data = failure_data.sort_values(by='failure_time', ascending=True)\n",
    "failure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b3f0745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>failure_time</th>\n",
       "      <th>disk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>MA1</td>\n",
       "      <td>2018-01-22 03:00:26</td>\n",
       "      <td>20195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>MA1</td>\n",
       "      <td>2018-01-22 03:19:40</td>\n",
       "      <td>22822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>MC1</td>\n",
       "      <td>2018-01-22 18:31:07</td>\n",
       "      <td>9578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>MA1</td>\n",
       "      <td>2018-01-23 03:19:28</td>\n",
       "      <td>15382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2018-01-23 03:19:46</td>\n",
       "      <td>3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>MC2</td>\n",
       "      <td>2019-12-31 16:16:05</td>\n",
       "      <td>12463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16066</th>\n",
       "      <td>MC2</td>\n",
       "      <td>2019-12-31 19:28:04</td>\n",
       "      <td>10186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13278</th>\n",
       "      <td>MC1</td>\n",
       "      <td>2019-12-31 19:32:50</td>\n",
       "      <td>18144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>MA2</td>\n",
       "      <td>2019-12-31 21:57:36</td>\n",
       "      <td>99516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>MB1</td>\n",
       "      <td>2019-12-31 22:58:47</td>\n",
       "      <td>29755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model        failure_time  disk_id\n",
       "1747    MA1 2018-01-22 03:00:26    20195\n",
       "1603    MA1 2018-01-22 03:19:40    22822\n",
       "6902    MC1 2018-01-22 18:31:07     9578\n",
       "1540    MA1 2018-01-23 03:19:28    15382\n",
       "508     MA2 2018-01-23 03:19:46     3417\n",
       "...     ...                 ...      ...\n",
       "16226   MC2 2019-12-31 16:16:05    12463\n",
       "16066   MC2 2019-12-31 19:28:04    10186\n",
       "13278   MC1 2019-12-31 19:32:50    18144\n",
       "602     MA2 2019-12-31 21:57:36    99516\n",
       "4402    MB1 2019-12-31 22:58:47    29755\n",
       "\n",
       "[16241 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为如果从20180101的错误开始计算，由于没有2018年之前的数据，所以这些输入会不匹配。因此我们直接从2018年1月10日的数据开始计算。\n",
    "filter_failure_data = pd.to_datetime('2018-01-22')\n",
    "failure_data = failure_data[failure_data['failure_time'] >= filter_failure_data]\n",
    "failure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "453a2735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure_time</th>\n",
       "      <th>disk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-01-20 09:59:49.750000128</td>\n",
       "      <td>101062.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2018-01-20 03:20:08</td>\n",
       "      <td>27780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018-01-20 03:22:58.249999872</td>\n",
       "      <td>57552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-01-20 04:44:47</td>\n",
       "      <td>93164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018-01-20 11:21:38.500000</td>\n",
       "      <td>136674.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018-01-21 03:09:37</td>\n",
       "      <td>190143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70119.373402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        failure_time        disk_id\n",
       "count                              4       4.000000\n",
       "mean   2018-01-20 09:59:49.750000128  101062.750000\n",
       "min              2018-01-20 03:20:08   27780.000000\n",
       "25%    2018-01-20 03:22:58.249999872   57552.000000\n",
       "50%              2018-01-20 04:44:47   93164.000000\n",
       "75%       2018-01-20 11:21:38.500000  136674.750000\n",
       "max              2018-01-21 03:09:37  190143.000000\n",
       "std                              NaN   70119.373402"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_date = pd.to_datetime('2018-01-22')\n",
    "\n",
    "filtered_data = failure_data[failure_data['failure_time'] < cutoff_date]\n",
    "filtered_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c191d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-03 03:00:26 2018-01-22 03:00:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:07<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# 获取failure_data第一条数据的failure_time字段，但是要判断最小的时间是否小于20180101\n",
    "from tqdm import tqdm\n",
    "smart_data_base_folder = '/mnt/raid5/sum/card/storage/StreamDFP/dataset/processed_smart_data'  # 设置为存放处理过的数据文件夹\n",
    "\n",
    "end_date = failure_data.iloc[0].failure_time\n",
    "start_date = max(end_date - timedelta(days=lookback_days - 1), pd.to_datetime('2018-01-01'))\n",
    "print(start_date, end_date)\n",
    "# 获取日期范围\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# 读取并合并 CSV 文件\n",
    "all_data = []\n",
    "\n",
    "for date in tqdm(date_range):\n",
    "    # 格式化日期为 YYYYMMDD\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    file_name = f\"{date_str}_processed.csv\"\n",
    "    \n",
    "    try:\n",
    "        # 读取 CSV 文件，并附加到 all_data 列表\n",
    "        df = pd.read_csv(os.path.join(smart_data_base_folder, file_name))\n",
    "        df['date'] = date_str  # 添加文件日期作为一列\n",
    "        all_data.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"文件 {file_name} 未找到，跳过该文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cd45f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_csv = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b08549f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disk_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>model</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_9</th>\n",
       "      <th>r_12</th>\n",
       "      <th>r_171</th>\n",
       "      <th>r_173</th>\n",
       "      <th>r_174</th>\n",
       "      <th>r_183</th>\n",
       "      <th>r_187</th>\n",
       "      <th>r_188</th>\n",
       "      <th>r_194</th>\n",
       "      <th>r_195</th>\n",
       "      <th>r_198</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>MA1</td>\n",
       "      <td>45406.0</td>\n",
       "      <td>27881.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>820719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20180103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24508.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20180103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100007</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32542.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20180103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100016</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>MC1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6974.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20180103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100024</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>MC1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20180103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952088</th>\n",
       "      <td>99902</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20697.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20180122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952089</th>\n",
       "      <td>99928</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20692.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20180122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952090</th>\n",
       "      <td>99958</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>MC1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4503.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20180122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952091</th>\n",
       "      <td>99977</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22234.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20180122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952092</th>\n",
       "      <td>99992</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24961.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20180122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6952093 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         disk_id          ds model      r_1      r_9  r_12  r_171  r_173  \\\n",
       "0              0  2018-01-03   MA1  45406.0  27881.0  32.0    0.0    0.0   \n",
       "1         100001  2018-01-03   MA2      NaN  24508.0  19.0    0.0    NaN   \n",
       "2         100007  2018-01-03   MA2      NaN  32542.0  24.0    0.0    NaN   \n",
       "3         100016  2018-01-03   MC1      0.0   6974.0  26.0    0.0   45.0   \n",
       "4         100024  2018-01-03   MC1      1.0   4626.0  23.0    0.0    3.0   \n",
       "...          ...         ...   ...      ...      ...   ...    ...    ...   \n",
       "6952088    99902  2018-01-22   MA2      NaN  20697.0  21.0    0.0    NaN   \n",
       "6952089    99928  2018-01-22   MA2      NaN  20692.0  17.0    0.0    NaN   \n",
       "6952090    99958  2018-01-22   MC1      0.0   4503.0  21.0    0.0   34.0   \n",
       "6952091    99977  2018-01-22   MA2      NaN  22234.0  13.0    0.0    NaN   \n",
       "6952092    99992  2018-01-22   MA2      NaN  24961.0  19.0    0.0    NaN   \n",
       "\n",
       "         r_174  r_183  r_187  r_188  r_194     r_195  r_198  label      date  \n",
       "0         30.0    NaN    0.0    0.0   15.0  820719.0    0.0      0  20180103  \n",
       "1         17.0    0.0    0.0    NaN   22.0       NaN    NaN      0  20180103  \n",
       "2         22.0    0.0    0.0    NaN   23.0       NaN    NaN      0  20180103  \n",
       "3         25.0    0.0    0.0   19.0   24.0       0.0    0.0      0  20180103  \n",
       "4         14.0    0.0    0.0   16.0   18.0       0.0    0.0      0  20180103  \n",
       "...        ...    ...    ...    ...    ...       ...    ...    ...       ...  \n",
       "6952088   17.0    0.0    0.0    NaN   26.0       NaN    NaN      0  20180122  \n",
       "6952089   11.0    0.0    0.0    NaN   26.0       NaN    NaN      0  20180122  \n",
       "6952090   20.0    0.0    0.0    0.0   19.0       0.0    0.0      0  20180122  \n",
       "6952091    8.0    0.0    0.0    NaN   28.0       NaN    NaN      0  20180122  \n",
       "6952092   17.0    0.0    0.0    NaN   22.0       NaN    NaN      0  20180122  \n",
       "\n",
       "[6952093 rows x 17 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e36d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:04,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:07,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 26\n",
      "Failure time: 2018-01-25 03:08:12, days: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:12,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:13,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:13,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:14,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:14,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of total_data: 34\n",
      "Failure time: 2018-01-27 03:01:11, days: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:20,  1.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(smart_data_base_folder, file_name))\n\u001b[1;32m     20\u001b[0m     new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_date_str\n\u001b[0;32m---> 21\u001b[0m     range_csv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrange_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m文件 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 未找到，跳过该文件\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sent_train/lib/python3.8/site-packages/pandas/core/reshape/concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sent_train/lib/python3.8/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/anaconda3/envs/sent_train/lib/python3.8/site-packages/pandas/core/internals/concat.py:232\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m#  than concat_compat\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "separator = '<SEP>'  # 使用的分隔符\n",
    "total_data = []\n",
    "for failure in tqdm(failure_data.itertuples()):\n",
    "    # 如果当前时间 - lookback_days > start_date, 则计算超过的时间\n",
    "    if failure.failure_time > end_date + timedelta(days=1):\n",
    "        days = (failure.failure_time - end_date).days\n",
    "        print(f'Failure time: {failure.failure_time}, days: {days}')\n",
    "        \n",
    "        # 删除 combined_data 中的 start_date 和 start_date+1 数据\n",
    "        range_csv = range_csv[~range_csv['date'].isin([start_date.strftime('%Y%m%d'), (start_date + timedelta(days=1)).strftime('%Y%m%d')])]\n",
    "        \n",
    "        # 加载并加入 end_date+1 和 end_date+2 的数据\n",
    "        for i in range(1, 3):\n",
    "            new_date = end_date + timedelta(days=i)\n",
    "            new_date_str = new_date.strftime('%Y%m%d')\n",
    "            file_name = f\"{new_date_str}_processed.csv\"\n",
    "            \n",
    "            try:\n",
    "                new_data = pd.read_csv(os.path.join(smart_data_base_folder, file_name))\n",
    "                new_data['date'] = new_date_str\n",
    "                range_csv = pd.concat([range_csv, new_data], ignore_index=True)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"文件 {file_name} 未找到，跳过该文件\")\n",
    "\n",
    "        # 更新 start_date 和 end_date\n",
    "        start_date = start_date + timedelta(days=2)\n",
    "        end_date = end_date + timedelta(days=2)\n",
    "\n",
    "        # print(\"更新后的 Combined Data:\")\n",
    "        # print(range_csv)\n",
    "        # print(f\"新 start_date: {start_date}, 新 end_date: {end_date}\")\n",
    "        # break\n",
    "    \n",
    "    # 从 failure 中获取 disk_id 和 model\n",
    "    disk_id = failure.disk_id\n",
    "    model = failure.model\n",
    "\n",
    "    # 在 range_csv 中筛选出 disk_id 和 model 与当前 failure 相同的数据\n",
    "    matching_data = range_csv[(range_csv['disk_id'] == disk_id) & (range_csv['model'] == model)]\n",
    "\n",
    "    # # 打印或处理匹配到的数据\n",
    "    # if not matching_data.empty:\n",
    "    #     print(f\"Matching data for disk_id={disk_id}, model={model}:\")\n",
    "    #     print(matching_data)\n",
    "    # else:\n",
    "    #     print(f\"No matching data found for disk_id={disk_id}, model={model}\")\n",
    "    \n",
    "    for start_idx in range(0, len(matching_data) - window_size + 1, step_size):\n",
    "        end_idx = start_idx + window_size\n",
    "        window = matching_data.iloc[start_idx:end_idx]  # 当前窗口数据\n",
    "        \n",
    "        # 序列化每个窗口的数据\n",
    "        serialized_data = []\n",
    "        for _, row in window.iterrows():\n",
    "            # 将单天数据转换为 [ds, r_1, r_9, ...] 格式\n",
    "            day_data = [row['ds']] + row.filter(regex='^r_').tolist()\n",
    "            serialized_data.extend(day_data)  # 将单天数据加入序列\n",
    "            serialized_data.append(separator)  # 插入分隔符\n",
    "        \n",
    "        serialized_data = serialized_data[:-1]  # 移除最后一个多余的分隔符\n",
    "        \n",
    "        total_data.append(serialized_data)\n",
    "    print(f'len of total_data: {len(total_data)}')\n",
    "    # print(failure)\n",
    "    # 获取其中某一列\n",
    "    # print(failure.failure_time)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f9df608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window.iloc[-1].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72022118-c9fd-4a09-9d7c-ea7d00a433a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_processed_data_for_day(file_path):\n",
    "    \"\"\"\n",
    "    加载处理后的SMART数据文件（每个日期的文件）\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def smart_data_generator(smart_data_base_folder, batch_size=10):\n",
    "    \"\"\"\n",
    "    生成器函数，分批读取CSV文件\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(smart_data_base_folder) if f.endswith('_processed.csv')]\n",
    "    \n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i + batch_size]\n",
    "        batch_data = []\n",
    "        \n",
    "        for filename in batch_files:\n",
    "            file_path = os.path.join(smart_data_base_folder, filename)\n",
    "            try:\n",
    "                smart_data = pd.read_csv(file_path)\n",
    "                smart_data['ds'] = pd.to_datetime(smart_data['ds'])\n",
    "                batch_data.append(smart_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {filename}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        if batch_data:\n",
    "            yield pd.concat(batch_data, ignore_index=True)\n",
    "\n",
    "def process_smart_data_for_disk(disk_id, model, start_time, end_time, smart_data_generator):\n",
    "    \"\"\"\n",
    "    处理单个磁盘的数据\n",
    "    \"\"\"\n",
    "    relevant_data = []\n",
    "    \n",
    "    for batch_data in smart_data_generator:\n",
    "        disk_data = batch_data[(batch_data['disk_id'] == disk_id) & \n",
    "                              (batch_data['model'] == model) & \n",
    "                              (batch_data['ds'] >= start_time) & \n",
    "                              (batch_data['ds'] <= end_time)]\n",
    "        if not disk_data.empty:\n",
    "            relevant_data.append(disk_data)\n",
    "    \n",
    "    return pd.concat(relevant_data, ignore_index=True) if relevant_data else pd.DataFrame()\n",
    "\n",
    "def generate_features_and_labels(failure_data, smart_data_base_folder, lookback_days, window_size, step_size):\n",
    "    \"\"\"\n",
    "    生成模型训练数据，按给定的滑动窗口选择特征和标签\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    failure_data = failure_data.sort_values(by='failure_time')\n",
    "    \n",
    "    # 创建一个字典来存储已处理过的磁盘数据\n",
    "    processed_disks = {}\n",
    "    \n",
    "    for failure in tqdm(failure_data.itertuples(), desc=\"Processing failure events\"):\n",
    "        failure_time = failure.failure_time\n",
    "        disk_id = failure.disk_id\n",
    "        model = failure.model\n",
    "        \n",
    "        # 计算时间范围\n",
    "        start_time = failure_time - timedelta(days=lookback_days)\n",
    "        end_time = failure_time\n",
    "        \n",
    "        # 获取磁盘数据\n",
    "        disk_key = f\"{disk_id}_{model}_{start_time}_{end_time}\"\n",
    "        if disk_key not in processed_disks:\n",
    "            relevant_smart_data = process_smart_data_for_disk(\n",
    "                disk_id, \n",
    "                model, \n",
    "                start_time, \n",
    "                end_time, \n",
    "                smart_data_generator(smart_data_base_folder)\n",
    "            )\n",
    "            processed_disks[disk_key] = relevant_smart_data\n",
    "        else:\n",
    "            relevant_smart_data = processed_disks[disk_key]\n",
    "\n",
    "        # 滑动窗口处理\n",
    "        for i in range(0, lookback_days - window_size + 1, step_size):\n",
    "            window_start_time = failure_time - timedelta(days=(lookback_days - i))\n",
    "            window_end_time = window_start_time + timedelta(days=window_size)\n",
    "            \n",
    "            window_data_for_window = relevant_smart_data[\n",
    "                (relevant_smart_data['ds'] >= window_start_time) & \n",
    "                (relevant_smart_data['ds'] < window_end_time)\n",
    "            ]\n",
    "            \n",
    "            if not window_data_for_window.empty:\n",
    "                values = window_data_for_window.drop(columns=['disk_id', 'label']).values.tolist()\n",
    "                last_window_data = window_data_for_window.iloc[-1]\n",
    "                label = last_window_data['label']\n",
    "                all_data.append({'data': values, 'label': label})\n",
    "                yield {'data': values, 'label': label}\n",
    "        # 清理不再需要的处理过的磁盘数据\n",
    "        if len(processed_disks) > 100:  # 保持缓存大小在可控范围内\n",
    "            processed_disks.clear()\n",
    "            \n",
    "    # return all_data\n",
    "\n",
    "# 使用方式保持不变\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e675d2-3b37-4ed2-b212-e8e6205cd095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing failure events: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "smart_data_base_folder = '/mnt/raid5/sum/card/storage/StreamDFP/dataset/processed_smart_data'\n",
    "failure_file_path = '/mnt/raid5/sum/card/storage/StreamDFP/dataset/ssd_failure_label.csv'\n",
    "\n",
    "failure_data = pd.read_csv(failure_file_path)\n",
    "failure_data['failure_time'] = pd.to_datetime(failure_data['failure_time'])\n",
    "\n",
    "lookback_days = 20\n",
    "window_size = 10\n",
    "step_size = 5\n",
    "\n",
    "dataset = generate_features_and_labels(failure_data, smart_data_base_folder, lookback_days, window_size, step_size)\n",
    "print(next(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1934edd4-fca1-42ed-8815-3c78974e01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "df_data = pd.read_csv(\"/mnt/raid5/sum/card/storage/StreamDFP/dataset/processed_smart_data/20180108_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c008a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7dff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单个csv文件数据的规模，行数：345542, 列数：16\n"
     ]
    }
   ],
   "source": [
    "print('单个csv文件数据的规模，行数：%d, 列数：%d' % (df_data.shape[0], df_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caada0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disk_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>model</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_9</th>\n",
       "      <th>r_12</th>\n",
       "      <th>r_171</th>\n",
       "      <th>r_173</th>\n",
       "      <th>r_174</th>\n",
       "      <th>r_183</th>\n",
       "      <th>r_187</th>\n",
       "      <th>r_188</th>\n",
       "      <th>r_194</th>\n",
       "      <th>r_195</th>\n",
       "      <th>r_198</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27122.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100034</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MC1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100039</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14976.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100047</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30425.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disk_id          ds model  r_1      r_9  r_12  r_171  r_173  r_174  r_183  \\\n",
       "0        1  2018-01-08   MB1  NaN   1015.0  16.0    NaN    NaN    NaN    0.0   \n",
       "1    10000  2018-01-08   MA2  NaN  27122.0  18.0    0.0    NaN   15.0    0.0   \n",
       "2   100034  2018-01-08   MC1  0.0   2226.0  20.0    0.0   12.0   16.0    0.0   \n",
       "3   100039  2018-01-08   MA2  NaN  14976.0  18.0    0.0    NaN   13.0    0.0   \n",
       "4   100047  2018-01-08   MA2  NaN  30425.0  13.0    0.0    NaN    8.0    0.0   \n",
       "\n",
       "   r_187  r_188  r_194  r_195  r_198  label  \n",
       "0    0.0    NaN   26.0    0.0    NaN      0  \n",
       "1    0.0    NaN   26.0    NaN    NaN      0  \n",
       "2    0.0   19.0   21.0    0.0    0.0      0  \n",
       "3    0.0    NaN   27.0    NaN    NaN      0  \n",
       "4    0.0    NaN   27.0    NaN    NaN      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c019cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disk_id</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_9</th>\n",
       "      <th>r_12</th>\n",
       "      <th>r_171</th>\n",
       "      <th>r_173</th>\n",
       "      <th>r_174</th>\n",
       "      <th>r_183</th>\n",
       "      <th>r_187</th>\n",
       "      <th>r_188</th>\n",
       "      <th>r_194</th>\n",
       "      <th>r_195</th>\n",
       "      <th>r_198</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>345542.000000</td>\n",
       "      <td>1.556570e+05</td>\n",
       "      <td>345527.000000</td>\n",
       "      <td>335759.000000</td>\n",
       "      <td>257696.000000</td>\n",
       "      <td>155657.000000</td>\n",
       "      <td>257698.000000</td>\n",
       "      <td>308036.000000</td>\n",
       "      <td>335759.000000</td>\n",
       "      <td>1.458900e+05</td>\n",
       "      <td>299525.000000</td>\n",
       "      <td>2.239510e+05</td>\n",
       "      <td>145892.000000</td>\n",
       "      <td>345542.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61223.214559</td>\n",
       "      <td>9.688713e+08</td>\n",
       "      <td>14332.037919</td>\n",
       "      <td>25.883768</td>\n",
       "      <td>3.064576</td>\n",
       "      <td>22.333207</td>\n",
       "      <td>22.127618</td>\n",
       "      <td>3.476555</td>\n",
       "      <td>1.420456</td>\n",
       "      <td>7.657148e+02</td>\n",
       "      <td>24.019170</td>\n",
       "      <td>4.315305e+07</td>\n",
       "      <td>0.020782</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>51055.696532</td>\n",
       "      <td>1.783724e+09</td>\n",
       "      <td>11120.241488</td>\n",
       "      <td>159.135721</td>\n",
       "      <td>282.019041</td>\n",
       "      <td>51.051952</td>\n",
       "      <td>165.794014</td>\n",
       "      <td>377.822162</td>\n",
       "      <td>239.019362</td>\n",
       "      <td>2.576359e+05</td>\n",
       "      <td>4.758325</td>\n",
       "      <td>2.126036e+08</td>\n",
       "      <td>1.209994</td>\n",
       "      <td>0.018001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21089.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4114.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42487.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>12011.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94458.750000</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>22714.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200207.000000</td>\n",
       "      <td>4.272667e+10</td>\n",
       "      <td>38756.000000</td>\n",
       "      <td>51208.000000</td>\n",
       "      <td>46424.000000</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>51205.000000</td>\n",
       "      <td>119867.000000</td>\n",
       "      <td>97861.000000</td>\n",
       "      <td>9.826090e+07</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.259553e+09</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             disk_id           r_1            r_9           r_12  \\\n",
       "count  345542.000000  1.556570e+05  345527.000000  335759.000000   \n",
       "mean    61223.214559  9.688713e+08   14332.037919      25.883768   \n",
       "std     51055.696532  1.783724e+09   11120.241488     159.135721   \n",
       "min         0.000000  0.000000e+00      10.000000       1.000000   \n",
       "25%     21089.000000  0.000000e+00    4114.000000      15.000000   \n",
       "50%     42487.000000  0.000000e+00   12011.000000      19.000000   \n",
       "75%     94458.750000  6.600000e+01   22714.000000      26.000000   \n",
       "max    200207.000000  4.272667e+10   38756.000000   51208.000000   \n",
       "\n",
       "               r_171          r_173          r_174          r_183  \\\n",
       "count  257696.000000  155657.000000  257698.000000  308036.000000   \n",
       "mean        3.064576      22.333207      22.127618       3.476555   \n",
       "std       282.019041      51.051952     165.794014     377.822162   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       9.000000       0.000000   \n",
       "50%         0.000000       5.000000      15.000000       0.000000   \n",
       "75%         0.000000      19.000000      21.000000       0.000000   \n",
       "max     46424.000000    1458.000000   51205.000000  119867.000000   \n",
       "\n",
       "               r_187         r_188          r_194         r_195  \\\n",
       "count  335759.000000  1.458900e+05  299525.000000  2.239510e+05   \n",
       "mean        1.420456  7.657148e+02      24.019170  4.315305e+07   \n",
       "std       239.019362  2.576359e+05       4.758325  2.126036e+08   \n",
       "min         0.000000  0.000000e+00       7.000000  0.000000e+00   \n",
       "25%         0.000000  2.000000e+00      22.000000  0.000000e+00   \n",
       "50%         0.000000  1.600000e+01      25.000000  0.000000e+00   \n",
       "75%         0.000000  5.200000e+01      27.000000  0.000000e+00   \n",
       "max     97861.000000  9.826090e+07     139.000000  4.259553e+09   \n",
       "\n",
       "               r_198          label  \n",
       "count  145892.000000  345542.000000  \n",
       "mean        0.020782       0.000324  \n",
       "std         1.209994       0.018001  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max       286.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f25280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disk_id         0\n",
       "ds              0\n",
       "model           0\n",
       "r_1        189885\n",
       "r_9            15\n",
       "r_12         9783\n",
       "r_171       87846\n",
       "r_173      189885\n",
       "r_174       87844\n",
       "r_183       37506\n",
       "r_187        9783\n",
       "r_188      199652\n",
       "r_194       46017\n",
       "r_195      121591\n",
       "r_198      199650\n",
       "label           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a69ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid hdds: 345430\n",
      "failed hdds: 112\n"
     ]
    }
   ],
   "source": [
    "valid = df_data[df_data['label'] == 0]\n",
    "failed = df_data[df_data['label'] == 1]\n",
    "print(\"valid hdds:\",len(valid))\n",
    "print(\"failed hdds:\",len(failed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a261959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5224ff5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disk_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>model</th>\n",
       "      <th>r_1</th>\n",
       "      <th>r_9</th>\n",
       "      <th>r_12</th>\n",
       "      <th>r_171</th>\n",
       "      <th>r_173</th>\n",
       "      <th>r_174</th>\n",
       "      <th>r_183</th>\n",
       "      <th>r_187</th>\n",
       "      <th>r_188</th>\n",
       "      <th>r_194</th>\n",
       "      <th>r_195</th>\n",
       "      <th>r_198</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MB1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MA2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27122.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100034</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MC1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100039</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MA2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14976.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100047</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>MA2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30425.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disk_id          ds model  r_1      r_9  r_12  r_171  r_173  r_174  r_183  \\\n",
       "0        1  2018-01-08   MB1  0.0   1015.0  16.0    0.0    0.0    0.0    0.0   \n",
       "1    10000  2018-01-08   MA2  0.0  27122.0  18.0    0.0    0.0   15.0    0.0   \n",
       "2   100034  2018-01-08   MC1  0.0   2226.0  20.0    0.0   12.0   16.0    0.0   \n",
       "3   100039  2018-01-08   MA2  0.0  14976.0  18.0    0.0    0.0   13.0    0.0   \n",
       "4   100047  2018-01-08   MA2  0.0  30425.0  13.0    0.0    0.0    8.0    0.0   \n",
       "\n",
       "   r_187  r_188  r_194  r_195  r_198  label  \n",
       "0    0.0    0.0   26.0    0.0    0.0      0  \n",
       "1    0.0    0.0   26.0    0.0    0.0      0  \n",
       "2    0.0   19.0   21.0    0.0    0.0      0  \n",
       "3    0.0    0.0   27.0    0.0    0.0      0  \n",
       "4    0.0    0.0   27.0    0.0    0.0      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
