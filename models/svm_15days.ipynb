{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# 定义数据加载函数\n",
    "def load_data_from_folder(folder_path):\n",
    "    all_data = []\n",
    "    # count = 0\n",
    "    for file in tqdm(os.listdir(folder_path)):\n",
    "        # if count > 5:\n",
    "        #     break\n",
    "        if file.endswith('.pkl'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                # count += 1\n",
    "                all_data.extend(data)  # 每个文件有 10000 条记录，合并到一起\n",
    "    return all_data\n",
    "\n",
    "# 数据处理函数\n",
    "def process_data(data_list, max_days=10, sep='<SEP>'):\n",
    "    X, y = [], []\n",
    "    for record in tqdm(data_list):\n",
    "        data = record['data']\n",
    "        label = record['label']\n",
    "        \n",
    "        # 数据预处理：分割 <SEP>，填充缺失值\n",
    "        split_data = \" \".join(map(str, data)).split(sep)\n",
    "        processed_record = []\n",
    "        \n",
    "        for day in split_data:\n",
    "            # 每天的数据：[时间戳, SMART1, SMART2, ...]\n",
    "            day_data = day.split()\n",
    "            if len(day_data) > 1:  # 如果有有效数据\n",
    "                try:\n",
    "                    smart_data = [0.0 if x == \"\\\\N\" else float(x) for x in day_data[1:]] # 跳过时间戳，转换为 float\n",
    "                except ValueError:\n",
    "                    print(f\"Error processing record: {day_data}\")\n",
    "                processed_record.extend(smart_data)\n",
    "            else:\n",
    "                processed_record.extend([0] * (len(processed_record) // max_days))  # 填充 0\n",
    "        \n",
    "        # 如果不足 max_days，进行填充\n",
    "        missing_days = max_days - len(processed_record) // (len(processed_record) // max_days)\n",
    "        for _ in range(missing_days):\n",
    "            processed_record.extend([0] * (len(processed_record) // max_days))\n",
    "        \n",
    "        X.append(processed_record)\n",
    "        y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 定义 SVM 模型\n",
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    scaler = StandardScaler()  # 数据标准化\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    model = SVC(kernel='rbf', probability=True)  # 使用 RBF 核的 SVM\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 模型预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
    "    \n",
    "    # 基本信息：标签为 0 和 1 的数量\n",
    "    num_zeros = sum(y_test == 0)\n",
    "    num_ones = sum(y_test == 1)\n",
    "    print(f\"Test set label counts - 0: {num_zeros}, 1: {num_ones}\")\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    # 计算 TPR 和 FPR\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    # 计算其他指标\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(f\"TPR (True Positive Rate): {tpr:.2f}\")\n",
    "    print(f\"FPR (False Positive Rate): {fpr:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(f\"AUC score: {auc:.2f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main(data_folder):\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data_from_folder(data_folder)\n",
    "    print(f\"Total records loaded: {len(data)}\")\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"No valid data found in the folder. Please check the data files.\")\n",
    "    \n",
    "    print(\"Processing data...\")\n",
    "    X, y = process_data(data)\n",
    "    print(f\"Processed Features Shape: {X.shape}, Labels Shape: {y.shape}\")\n",
    "    if X.shape[0] == 0:\n",
    "        raise ValueError(\"Processed data is empty. Please check the preprocessing steps.\")\n",
    "    \n",
    "    print(\"Splitting dataset...\")\n",
    "    if len(X) < 5:\n",
    "        print(\"Insufficient data for train-test split. Using all data for training.\")\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = X, y\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"Filling NaN values with 0...\")\n",
    "    X_train = np.nan_to_num(X_train, nan=0)\n",
    "    X_test = np.nan_to_num(X_test, nan=0)\n",
    "    \n",
    "    print(\"Training SVM model...\")\n",
    "    model = train_svm(X_train, y_train, X_test, y_test)\n",
    "    print(\"Model training complete.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records loaded: 61246\n",
      "Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61246/61246 [00:06<00:00, 9711.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Features Shape: (61246, 180), Labels Shape: (61246,)\n",
      "Splitting dataset...\n",
      "Filling NaN values with 0...\n",
      "Training SVM model...\n",
      "Test set label counts - 0: 7724, 1: 4526\n",
      "Accuracy: 0.6302040816326531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77      7724\n",
      "           1       0.00      0.00      0.00      4526\n",
      "\n",
      "    accuracy                           0.63     12250\n",
      "   macro avg       0.32      0.50      0.39     12250\n",
      "weighted avg       0.40      0.63      0.49     12250\n",
      "\n",
      "TPR (True Positive Rate): 0.00\n",
      "FPR (False Positive Rate): 0.00\n",
      "F1-score: 0.00\n",
      "AUC score: 0.55\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"/mnt/raid5/sum/card/storage/AI4Storage/datasets/norm_10ahead_15window\"  # 替换为你的数据文件夹路径\n",
    "svm_model = main(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records loaded: 61246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"/mnt/raid5/sum/card/storage/AI4Storage/datasets/norm_10ahead_15window\"  # 替换为你的数据文件夹路径\n",
    "data = load_data_from_folder(data_folder)  # 加载数据\n",
    "print(f\"Total records loaded: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'disk_id': 50079,\n",
       "  'model': 'MC1',\n",
       "  'data': [20180107,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180108,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180109,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180110,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180111,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180112,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180113,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180114,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180115,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180116,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180117,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180118,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180119,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180120,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180121,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0],\n",
       "  'label': 0},\n",
       " {'disk_id': 50079,\n",
       "  'model': 'MC1',\n",
       "  'data': [20180112,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180113,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180114,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180115,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180116,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180117,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180118,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180119,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180120,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180121,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180122,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180123,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180124,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180125,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180126,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0],\n",
       "  'label': 0},\n",
       " {'disk_id': 50079,\n",
       "  'model': 'MC1',\n",
       "  'data': [20180117,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180118,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180119,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180120,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180121,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180122,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180123,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180124,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180125,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180126,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180127,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180128,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180129,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180130,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180131,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   99.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0],\n",
       "  'label': 1},\n",
       " {'disk_id': 122876,\n",
       "  'model': 'MC1',\n",
       "  'data': [20180102,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   '<SEP>',\n",
       "   20180103,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180104,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180105,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180106,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180107,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180108,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180109,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180110,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180111,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180112,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180113,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180114,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180115,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180116,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0],\n",
       "  'label': 0},\n",
       " {'disk_id': 122876,\n",
       "  'model': 'MC1',\n",
       "  'data': [20180107,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180108,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180109,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180110,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180111,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180112,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180113,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180114,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180115,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180116,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180117,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   77.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180118,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180119,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180120,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   '<SEP>',\n",
       "   20180121,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   76.0,\n",
       "   100.0,\n",
       "   100.0],\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disk_id': 16491, 'model': 'MA1', 'data': [20180116, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180117, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180118, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180119, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180120, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180121, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180122, 130.0, 100.0, 100.0, 100.0, 3.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180123, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180124, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180125, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180126, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180127, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180128, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180129, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0, '<SEP>', 20180130, 130.0, 100.0, 100.0, 100.0, 2.0, 100.0, nan, 100.0, 100.0, 100.0, 100.0, 100.0], 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "for record in data:\n",
    "    if record['model'] != 'MC1' and record['label'] == 1:\n",
    "        print(record)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = process_data(data)  # 处理数据\n",
    "print(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample record: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample record:\", data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sent_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
